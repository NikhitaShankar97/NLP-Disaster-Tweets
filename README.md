# ğŸ† Natural Language Processing with Disaster Tweets  
[![Kaggle](https://img.shields.io/badge/Kaggle-Competition-blue?style=flat&logo=kaggle)](https://www.kaggle.com/competitions/nlp-getting-started)  

## ğŸ“Œ Overview  
This project is part of the **Kaggle NLP Competition - Natural Language Processing with Disaster Tweets**. The objective is to build a **machine learning model that classifies tweets as either related to real disasters or not**.  

Tweets often contain **metaphors, sarcasm, or unrelated context**, making this an **interesting and challenging NLP task** that goes beyond simple keyword matching.  

---

## ğŸ’‚ Dataset  
The dataset consists of tweets labeled as **disaster (1) or non-disaster (0)**, along with metadata such as **keywords and location**.  

### ğŸŒŸ Data Files:
- **`train.csv`** â†’ 7,613 tweets with labels (`target = 1` for disaster, `target = 0` for non-disaster)  
- **`test.csv`** â†’ 3,263 tweets without labels (used for predictions)  
- **`sample_submission.csv`** â†’ Example submission format for Kaggle  

---

## ğŸ” Exploratory Data Analysis (EDA)  
Key observations from **EDA & feature analysis**:  
ğŸ‘‰ **Keyword Influence**: Some words (e.g., `"earthquake"`, `"wildfire"`, `"flood"`) are strong indicators of disaster tweets.  
ğŸ‘‰ **Tweet Length**: Disaster tweets **tend to be slightly longer** (word & character count).  
ğŸ‘‰ **Special Tokens**: More **hashtags, URLs (news links), and exclamation marks** appear in disaster-related tweets.  
ğŸ‘‰ **Location Data**: **~33% of tweets lack location info**, reducing its predictive power.  

---

## ğŸ° Model Pipeline  
This project explores multiple NLP techniques, ranging from traditional machine learning models to state-of-the-art transformers.  

### **1ï¸âƒ£ Text Preprocessing**
ğŸ‘‰ Tokenization using **Hugging Face Transformers**  
ğŸ‘‰ Lowercasing, removing URLs, mentions, hashtags  
ğŸ‘‰ Handling missing metadata (`no_keyword`, `no_location`)  

### **2ï¸âƒ£ Feature Engineering**
ğŸ‘‰ Extracting word & character count features  
ğŸ‘‰ Analyzing special tokens (hashtags, mentions, URLs, exclamations)  
ğŸ‘‰ Embeddings from pre-trained transformers  

### **3ï¸âƒ£ Model Training & Validation**
ğŸ‘‰ **Baseline Models**: TF-IDF + Logistic Regression  
ğŸ‘‰ **Deep Learning Approaches**: LSTMs, GRUs  
ğŸ‘‰ **Transformer Models**:  
   - **BERT (`bert-base-uncased`)**  
   - **DistilBERT (`distilbert-base-uncased`)**  
   - **BERTweet (`vinai/bertweet-base`)** â†’ ğŸš€ **Final Model**  

ğŸ‘‰ **Training Strategies**
- **3-Fold Stratified Cross-Validation**  
- **Early Stopping** (to prevent overfitting)  
- **Gradient Accumulation** (for better memory efficiency)  
- **Learning Rate Scheduling** (**Cosine Decay with Warmup**)  

---

## ğŸ“Š Results & Insights  
| **Model**        | **Validation Accuracy** | **F1 Score** | **Inference Time** |
|----------------|-------------------|------------|----------------|
| TF-IDF + Logistic Regression | 0.78 | 0.74 | âš¡ Very Fast |
| DistilBERT | 0.83 | 0.81 | ğŸš€ Fast |
| **BERTweet (Final Model)** | **0.86** | **0.84** | âš¡âš¡ Moderate |

ğŸ‘‰ The **BERTweet model** achieved the highest accuracy and F1-score, leveraging its **pretraining on social media text**.  
ğŸ‘‰ **DistilBERT provided a balance** between speed and accuracy.  
ğŸ‘‰ **Traditional models performed decently** but lacked contextual understanding of tweets.  

---

## ğŸ“ˆ Next Steps  
ğŸ‘‰ **Fine-tune hyperparameters further** using Optuna/W&B Sweeps  
ğŸ‘‰ **Experiment with GPT-based models** for improved contextual understanding  
ğŸ‘‰ **Deploy the best model** as an API for real-time disaster tweet classification  

---

## ğŸ¤ Connect with Me  
If you found this project interesting or have any suggestions, feel free to connect!  

ğŸ“§ **Email**: [nikhita.shankar97@gmail.com](mailto:nikhita.shankar97@gmail.com)  
ğŸ‘‰ **LinkedIn**: [linkedin.com/in/nikhita-shankar-/](https://linkedin.com/in/nikhita-shankar-/)  

---

### â­ If you found this useful, consider giving the repository a star! â­  
